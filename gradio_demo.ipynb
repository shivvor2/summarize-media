{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo (in gradio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from typing import Optional\n",
    "\n",
    "from summarize_media.get_media.youtube import get_youtube\n",
    "from summarize_media.pre_processing.convert_audio_format import convert_to_wav\n",
    "from summarize_media.transcribe.transcribe_cloud import get_transcribe_cloud\n",
    "from summarize_media.host_files.host_files import upload_file_to_0x0\n",
    "from summarize_media.post_processing.reformat_output import reformat\n",
    "from summarize_media.summarize_transcription.summarize import get_summarization\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard coded for demo purposes\n",
    "media_output_path = \"data/media\"\n",
    "transcript_output_path = \"data/transcript\"\n",
    "local_size_limit = 40 # in MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(file_path: str):\n",
    "    _, name = os.path.split(file_path)\n",
    "    name, _ = os.path.splitext(name)\n",
    "    return name\n",
    "\n",
    "def pipeline(url: str, \n",
    "             sampling_rate: int = 16000, \n",
    "             save_results = False, \n",
    "             output_path: Optional[str] = None,\n",
    "             cloud_transcribe_model_name: str = \"large-v3\",\n",
    "             cloud_transcribe_kwargs: Optional[dict] = None):\n",
    "    # Fetching Audio from youtube and converting to wav\n",
    "    audio = get_youtube(url, media_output_path)\n",
    "    name = get_name(audio)\n",
    "    \n",
    "    audio = convert_to_wav(audio, sample_rate=sampling_rate)\n",
    "\n",
    "    # Directly supply the file for inference or upload the file depending on size\n",
    "    size = os.path.getsize(audio)\n",
    "    print(f\"Converted audio size: {(size / 1024) /1024:.1f} MB\")\n",
    "    if size < local_size_limit * 1024 * 1024:\n",
    "        print(\"Upload file directly to inference endpoint\")\n",
    "        audio = open(audio, \"rb\")\n",
    "    else:\n",
    "        print(\"Exceeded size limit, uploading to file host before performing inference\")\n",
    "        audio = upload_file_to_0x0(audio, 3600)\n",
    "        print(\"Uploaded File\")\n",
    "        \n",
    "\n",
    "    # Transcribing and reformating the audio\n",
    "    print(\"Starting transcription process\")\n",
    "    cloud_transcribe_kwargs = cloud_transcribe_kwargs if cloud_transcribe_kwargs else {}\n",
    "    transcript = get_transcribe_cloud(audio, \n",
    "                                      model_name=cloud_transcribe_model_name, \n",
    "                                      **cloud_transcribe_kwargs)\n",
    "    transcript = transcript[\"segments\"]\n",
    "    transcript_txt = reformat(transcript)\n",
    "    summary_txt =  get_summarization(transcript_txt)\n",
    "    \n",
    "    output_path = output_path if output_path else transcript_output_path\n",
    "    transcript_json_path = os.path.join(output_path, name + \".json\")\n",
    "    transcript_txt_path = os.path.join(output_path, name + \".txt\")\n",
    "    \n",
    "    if save_results and output_path:\n",
    "        with open(transcript_json_path, 'w') as file:\n",
    "            json.dump(transcript, file)\n",
    "            \n",
    "        with open(transcript_txt_path, \"w\") as file:\n",
    "            file.write(transcript_txt) \n",
    "        \n",
    "    return summary_txt, transcript_txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_local_file(file_path: str, \n",
    "                        sampling_rate: int = 16000, \n",
    "                        save_results = False, \n",
    "                        output_path: Optional[str] = None,\n",
    "                        cloud_transcribe_model_name: str = \"large-v2\",\n",
    "                        cloud_transcribe_kwargs: Optional[dict] = None):\n",
    "    \n",
    "    name = get_name(file_path)\n",
    "    audio = convert_to_wav(file_path, sample_rate=sampling_rate)\n",
    "    cloud_transcribe_kwargs = cloud_transcribe_kwargs if cloud_transcribe_kwargs else {}\n",
    "\n",
    "    # Directly supply the file for inference or upload the file depending on size\n",
    "    size = os.path.getsize(audio)\n",
    "    print(f\"Converted audio size: {(size / 1024) /1024:.1f} MB\")\n",
    "    if size < local_size_limit * 1024 * 1024:\n",
    "        print(\"Upload file directly to inference endpoint\")\n",
    "        audio = open(audio, \"rb\")\n",
    "    else:\n",
    "        print(\"Exceeded size limit, uploading to file host before performing inference\")\n",
    "        audio = upload_file_to_0x0(audio, 3600)\n",
    "        print(\"Uploaded File\")\n",
    "        \n",
    "\n",
    "    # Transcribing and reformating the audio\n",
    "    \n",
    "    print(\"Start Transcription\")\n",
    "    transcript = get_transcribe_cloud(audio, \n",
    "                                      model_name=cloud_transcribe_model_name, \n",
    "                                      **cloud_transcribe_kwargs)\n",
    "    transcript_txt = reformat(transcript)\n",
    "    summary_txt =  get_summarization(transcript_txt)\n",
    "    \n",
    "    transcript_json_path = os.path.join(output_path, name + \".json\")\n",
    "    transcript_txt_path = os.path.join(output_path, name + \".txt\")\n",
    "    \n",
    "    if save_results and output_path:\n",
    "        with open(transcript_json_path, 'w') as file:\n",
    "            json.dump(transcript, file)\n",
    "            \n",
    "        with open(transcript_txt_path, \"w\") as file:\n",
    "            file.write(transcript_txt) \n",
    "        \n",
    "    return summary_txt, transcript_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_pipeline(url: str, sampling_rate: int = 16000):\n",
    "    try:\n",
    "        summary, transcript = pipeline(url, sampling_rate)\n",
    "        return summary, transcript\n",
    "    except Exception as e:\n",
    "        return str(e), \"Failed to get transcription\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivvorz/anaconda3/envs/summarize-media/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/gradio-messaging/en \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/v3/tunnel-request \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on public URL: https://eaf28e749992caa370.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: HEAD https://eaf28e749992caa370.gradio.live \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://eaf28e749992caa370.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Why Can't We Make Simple Software? - Peter van Hardenberg\n",
      "Upload date: 27/11/24 09:00:40\n",
      "Time length: 0:41:33\n",
      " ↳ |████████████████████████████████████████████| 100.0%\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:summarize_media.host_files.host_files:Uploading file: Why Can't We Make Simple Software? - Peter van Hardenberg.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted audio size: 152.2 MB\n",
      "Exceeded size limit, uploading to file host before performing inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:summarize_media.host_files.host_files:Successfully uploaded to https://0x0.st/XRnJ.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded File\n",
      "Starting transcription process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.replicate.com/v1/predictions \"HTTP/1.1 201 Created\"\n",
      "INFO:httpx:HTTP Request: GET https://api.replicate.com/v1/models/victor-upmeet/whisperx/versions/84d2ad2d6194fe98a17d2b60bef1c7f910c46b2f6fd38996ca457afd9c8abfcb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\n",
    "    \"\"\"\n",
    "    # Media Summarizer\n",
    "    \n",
    "    Summarizes and transcribes a youtube video.\n",
    "    \n",
    "    Feedback: [Google form](https://forms.gle/RT66bre2X9B9s4d79) or dm me (twitter(X):shivvor2 or discord: shz2__)\n",
    "    \n",
    "    Wait time is ~5-10 mins (my internet is slow) and there are issues for super long (3+ hour) videos (file size cap for hosting service im using)\n",
    "    \n",
    "    \"\"\"\n",
    "    )\n",
    "    input = gr.Textbox(label = \"url\", placeholder = \"Please input a valid youtube url\") \n",
    "    sampling_rate = gr.Slider(value=16000, minimum=8000, maximum=24000, step=100, label = \"Audio Sample Rate\")\n",
    "    out_summary = gr.Markdown(label = \"summary\")\n",
    "    out_transcript = gr.Textbox(label = \"transcript\")\n",
    "    start_btn = gr.Button(\"Un-NotebookLM's your podcast\")\n",
    "    start_btn.click(fn = demo_pipeline, \n",
    "                    inputs = input, \n",
    "                    outputs = [out_summary, out_transcript]\n",
    "                    )\n",
    "\n",
    "demo.launch(share = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summarize-media",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
